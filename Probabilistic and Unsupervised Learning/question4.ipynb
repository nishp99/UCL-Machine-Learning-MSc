{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "509dfaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import groupby\n",
    "from itertools import zip_longest\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "import scipy as sp\n",
    "import math\n",
    "from scipy import special\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "1bdabe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['=', ' ', '-', ',', ';', ':', '!', '?', '/', '.', \"'\", '\"', '(', ')', '[', ']', '*', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The following defines all the texts as lists we can iterate over\n",
    "\"\"\"\n",
    "\n",
    "text_1 = list(open(\"englishtext.txt\",encoding='utf8').read())\n",
    "text_2 = [' ' if x=='\\n' else x for x in text_1]\n",
    "text = [x.lower() for x in text_2]\n",
    "\n",
    "seen = text[0]\n",
    "cleaned_text = [text[0]]\n",
    "for i in text[1:]:\n",
    "    if i == ' ':\n",
    "        if i != seen:\n",
    "            cleaned_text.append(i)\n",
    "        seen = i\n",
    "    else:\n",
    "        cleaned_text.append(i)\n",
    "        seen = i\n",
    "    \n",
    "\n",
    "symbols_1 = list(open(\"symbols.txt\",encoding='utf8').read())\n",
    "symbols = list(filter(('\\n').__ne__, symbols_1))\n",
    "symbol_set = set(symbols)\n",
    "symbol_pairs = []\n",
    "for i in symbols:\n",
    "    for j in symbols:\n",
    "        symbol_pairs.append((i,j))\n",
    "\n",
    "symbol_pairs_set = set(symbol_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "2652d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_1 = list(open('message.txt',encoding='utf8').read())\n",
    "message = list(filter(('\\n').__ne__, message_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "cd8c425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_1 = dict(Counter(cleaned_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "70a55fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cleaned_dict contains counts of all 53 symbols and no others\n",
    "\"\"\"\n",
    "cleaned_dict = dict((k, dictionary_1[k]) for k in set(dictionary_1) & symbol_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "31b7b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cleaned_dict_pairs contains counts of every consecutively occurring pairs of symbols (in both orders)\n",
    "symbol_pairs is a list of all possible pair combinations (both orders included) \n",
    "\"\"\"\n",
    "dict_pairs = Counter(zip(cleaned_text, cleaned_text[1:]))\n",
    "cleaned_dict_pairs = dict((k,dict_pairs[k]) for k in set(dict_pairs) & symbol_pairs_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "3bc24438",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "define transition matrix full of zeros\n",
    "resulting is matrix P where P[i][j] is proportional to prob from going from i to j (row to column)\n",
    "\"\"\"\n",
    "\n",
    "P = torch.zeros((53,53))\n",
    "\n",
    "for i in range(53):\n",
    "    for j in range(53):\n",
    "        try:\n",
    "            P[i][j] = cleaned_dict_pairs[(symbols[i],symbols[j])]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "\"\"\"\n",
    "defines a different matrix for test case\n",
    "\"\"\"\n",
    "\n",
    "test_P = (torch.ones_like(P) + P).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "2567f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "count_vector contains a vector of counts of the symbols (in the same order as P)\n",
    "\"\"\"\n",
    "count_vector = torch.zeros(53)\n",
    "for i in range(53):\n",
    "    count_vector[i] = cleaned_dict[symbols[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "1f530f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "we normalise the rows of P to sum to 1, then transpose to get the transition matrix\n",
    "\"\"\"\n",
    "normalisers = torch.sum(P,1)\n",
    "normalised_P = (torch.diag(torch.div(torch.ones(normalisers.size()),normalisers)) @ P).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "32ac18f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nthe transition matrix estimate is not aperiodic (and may not be irreducible),\\nwe make it aperiodic and irreducible by adding a*torch.ones(P.size()) to P.\\nwhere 'a' is decided by heuristics, we choose a=min(P)\\x00. we then normalise to make\\nthe columns sum to one\\n\""
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "the transition matrix estimate is not aperiodic (and may not be irreducible),\n",
    "we make it aperiodic and irreducible by adding a*torch.ones(P.size()) to P.\n",
    "where 'a' is decided by heuristics, we choose a=min(P)\\0. we then normalise to make\n",
    "the columns sum to one\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "0cc84982",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "finds the minimum value excluding 0 in the transition matrix\n",
    "\"\"\"\n",
    "minimum = 1\n",
    "count= 0\n",
    "for i in normalised_P:\n",
    "    for j in range(53):\n",
    "        if i[j] != 0 and i[j]<minimum:\n",
    "            minimum = i[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "ef80b8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regulariser = minimum*torch.ones_like(normalised_P)\n",
    "irrep_P = normalised_P + regulariser\n",
    "\n",
    "row_normalisers = torch.sum(irrep_P,0)\n",
    "transition_M = irrep_P @ torch.diag(torch.div(torch.ones_like(row_normalisers),row_normalisers))\n",
    "\n",
    "plt.imshow(transition_M, interpolation='nearest')\n",
    "plt.savefig('transitionm.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "40d0158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "we now find the stationary distribution\n",
    "\"\"\"\n",
    "\n",
    "init_p_1 = torch.full((53,),1/53)\n",
    "\n",
    "for _ in range(100):\n",
    "    init_p_1 = transition_M @ init_p_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "fb9a2828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "stat_p = init_p_1\n",
    "print(torch.sum(stat_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "9dc70b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create a dictionary for the stationary distribution\n",
    "\"\"\"\n",
    "\n",
    "list_1 = [x.item() for x in stat_p]\n",
    "invariant_dict = dict(zip(symbols,list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "ea2409ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol   invariant probability\n",
      "=        2.438e-06      \n",
      "         1.793e-01      \n",
      "-        5.821e-04      \n",
      ",        1.260e-02      \n",
      ";        3.608e-04      \n",
      ":        3.208e-04      \n",
      "!        1.243e-03      \n",
      "?        9.887e-04      \n",
      "/        4.709e-06      \n",
      ".        1.001e-02      \n",
      "'        4.016e-06      \n",
      "\"        8.886e-06      \n",
      "(        2.156e-04      \n",
      ")        2.139e-04      \n",
      "[        2.438e-06      \n",
      "]        2.582e-06      \n",
      "*        9.462e-05      \n",
      "0        6.155e-05      \n",
      "1        1.299e-04      \n",
      "2        4.880e-05      \n",
      "3        2.129e-05      \n",
      "4        9.389e-06      \n",
      "5        1.900e-05      \n",
      "6        2.051e-05      \n",
      "7        1.511e-05      \n",
      "8        6.533e-05      \n",
      "9        1.346e-05      \n",
      "a        6.423e-02      \n",
      "b        1.090e-02      \n",
      "c        1.951e-02      \n",
      "d        3.751e-02      \n",
      "e        9.940e-02      \n",
      "f        1.746e-02      \n",
      "g        1.622e-02      \n",
      "h        5.314e-02      \n",
      "i        5.426e-02      \n",
      "j        8.124e-04      \n",
      "k        6.357e-03      \n",
      "l        3.018e-02      \n",
      "m        1.948e-02      \n",
      "n        5.773e-02      \n",
      "o        6.031e-02      \n",
      "p        1.446e-02      \n",
      "q        7.408e-04      \n",
      "r        4.707e-02      \n",
      "s        4.957e-02      \n",
      "t        7.103e-02      \n",
      "u        2.041e-02      \n",
      "v        8.040e-03      \n",
      "w        1.849e-02      \n",
      "x        1.399e-03      \n",
      "y        1.437e-02      \n",
      "z        5.609e-04      \n"
     ]
    }
   ],
   "source": [
    "print (\"{:<8} {:<15}\".format('Symbol','invariant probability'))\n",
    "for k,v in invariant_dict.items():\n",
    "    print(\"{:<8} {:<15}\".format(k, '{:.3e}'.format(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "c5b0cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "a dictionary specifying the order of the symbols in the transition matrix and\n",
    "invariant distribution (key is symbol, key-value is index in matrix/vector)\n",
    "\"\"\"\n",
    "\n",
    "master_dict = dict(zip(symbols,range(0,53)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "d3d60244",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dictionary corresponding to the identity permutation (for test cases)\n",
    "\"\"\"\n",
    "def identity_perm():\n",
    "    identity_perm = dict(zip(symbols,symbols)), [symbols,symbols]\n",
    "    return identity_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "a0db470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "initialise random permutation\n",
    "\"\"\"\n",
    "def init_perm():\n",
    "    L = [0,0]\n",
    "    L_1 = symbols\n",
    "    L_0 = random.sample(symbols,53)\n",
    "    \n",
    "    L[0] = L_0\n",
    "    L[1] = L_1\n",
    "    return dict(zip(L_0,L_1)), L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "d51d9d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "returns the invariant probability of the pre-image of a message symbol under\n",
    "some permutation\n",
    "\"\"\"\n",
    "def invariant_prob_preimage(a,perm):\n",
    "    index = master_dict[perm[a]]\n",
    "    return stat_p[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "d9a95051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "returns the element of transition matrix indexed by the pre-images of of two message\n",
    "symbols under some permutation\n",
    "\"\"\"\n",
    "def transition_prob_preimages(a,b,perm):\n",
    "    index_1, index_2 = master_dict[perm[b]], master_dict[perm[a]]\n",
    "    \n",
    "    #return transition_M[index_1][index_2]\n",
    "    return test_P[index_1][index_2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "f157b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "finds the log-likelihood of the message given a permutation\n",
    "\"\"\"\n",
    "def log_likelihood(perm):\n",
    "    \"\"\"log_prob = torch.log(invariant_prob_preimage(message[0],perm))\n",
    "    for i in range(len(message)-1):\n",
    "        log_prob += torch.log(transition_prob_preimages(message[i],message[i+1],perm))\"\"\"\n",
    "    \n",
    "    log_prob = 0\n",
    "    for i in range(len(message)-1):\n",
    "        log_prob += torch.log(transition_prob_preimages(message[i],message[i+1],perm))\n",
    "    \n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "51c4e1cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_u = identity_perm()[0]\\ntest_v  = identity_perm()[1]\\ntest_swap = swap_values(test_u,test_v)\\nprint(test_u)\\nprint(test_swap[0])\\nprint(test_v)\\nprint(test_swap[1])'"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "swaps two random symbols to generate a new permutation\n",
    "\"\"\"\n",
    "def swap_values(u,v):\n",
    "    a, b = random.randrange(53), random.randrange(53)\n",
    "    while a == b:\n",
    "        a, b = random.randrange(53), random.randrange(53)\n",
    "    \n",
    "    new_u = u.copy()\n",
    "    new_v = v.copy()\n",
    "    \n",
    "    symbol_1 = v[0][a]\n",
    "    symbol_2 = v[0][b]\n",
    "    \n",
    "    \n",
    "    new_v[0][a] = symbol_2\n",
    "    new_v[0][b] = symbol_1\n",
    "     \n",
    "    a = u[symbol_1]\n",
    "    b = u[symbol_2]\n",
    "    \n",
    "    new_u[symbol_1] = b\n",
    "    new_u[symbol_2] = a\n",
    "    \n",
    "    return new_u, new_v\n",
    "\n",
    "\n",
    "\"\"\"test_u = identity_perm()[0]\n",
    "test_v  = identity_perm()[1]\n",
    "test_swap = swap_values(test_u,test_v)\n",
    "print(test_u)\n",
    "print(test_swap[0])\n",
    "print(test_v)\n",
    "print(test_swap[1])\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "629c1ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print the message given some permutation\n",
    "\"\"\"\n",
    "def print_decrypted_message(perm,length):\n",
    "    replacer = perm.get\n",
    "    \n",
    "    message_list = [replacer(n,n) for n in message]\n",
    "    decrypted_message = \"\"\n",
    "    for x in message_list:\n",
    "        decrypted_message += x\n",
    "    print(decrypted_message[:length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "03a17f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "returns boolean specifying whether to go from permutation t to permutation t+1\n",
    "\"\"\"\n",
    "\n",
    "def acceptance(perm_1,perm_2):\n",
    "    a = log_likelihood(perm_2).item()\n",
    "    b = log_likelihood(perm_1).item()\n",
    "    \"\"\"print(a)\n",
    "    print(b)\n",
    "    print(a-b)\"\"\"\n",
    "    log_ratio = a - b\n",
    "    \"\"\"print(log_ratio)\"\"\"\n",
    "    log_acceptance_prob = min(0,log_ratio)\n",
    "    \"\"\"print(log_acceptance_prob)\"\"\"\n",
    "    a = dist.Uniform(0,1).sample()\n",
    "    \"\"\"print(math.log(a))\"\"\"\n",
    "    if math.log(a) <= log_acceptance_prob:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "16df9103",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "defines one round of the MCMC sampler, starting from some starting permutation\n",
    "\"\"\"\n",
    "def MCMC_round(perm_dict,perm_list):\n",
    "    new_dict, new_list = swap_values(perm_dict,perm_list)\n",
    "    if acceptance(perm_dict,new_dict):\n",
    "        return new_dict, new_list\n",
    "    else:\n",
    "        return perm_dict, perm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "576cda3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCMC(N_iter):\n",
    "    perm_dict, perm_list = init_perm()\n",
    "    for i in range(N_iter):\n",
    "        perm_dict, perm_list = MCMC_round(perm_dict,perm_list)\n",
    "        if i%100 == 0:\n",
    "            print_decrypted_message(perm_dict,60)\n",
    "        if i == N_iter-1:\n",
    "            print_decrypted_message(perm_dict,len(message))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "a54d5892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v:!g;!;?1:m=,!2:h!g?,=! 1w:=,2yw=!;=2,i!g;![2q*=,!m2 =!g=!i?\n",
      "s;ig:i:z ;mfuit;higzufi, a;futyafi:ftueig:icto8fuimt,figfiez\n",
      "n il:i:b; vfuit hilbufi,;a futpafi:ftueil:ictosfuivt,filfieb\n",
      "s ilwiwc; vruit hilcuri,;a rutmariwrtueilwidtonruivt,rilriec\n",
      "s ilwiwnm druit hilnuriyma rut;ariwrtueilwivtocruidtyrilrien\n",
      "s ifwiwng pruit hifnuriyga rut;ariwrtueifwivtocruiptyrifrien\n",
      "s efwewng prcet hefncredga rct!arewrtciefwevtourceptdrefrein\n",
      "s efwewng prcet hefncredgl rct!lrewrtciefwevtourceptdrefrein\n",
      "s efwewng prcet hefncredgl rct!lrewrtciefwevtourceptdrefrein\n",
      "s eawewng prcet heancredgl rct!lrewrtcieawevtourceptdrearein\n",
      "r eawewng pslet heanlsedgc slt!csewstlieawevtousleptdseasein\n",
      "re aw wndepsl teh anls fdceslt(cs wstli aw vtousl ptfs as in\n",
      "re aw wndepil tey anli fdceiltbci witls aw vtouil ptfi ai sn\n",
      "re aw wndepil tey anli fdceiltbci witls aw vtouil ptfi ai sn\n",
      "re aw wndepil tey anli vdceiltbci witls aw ftouil ptvi ai sn\n",
      "re aw wndepil tey anli vdceiltbci witls aw ftouil ptvi ai sn\n",
      "re aw wndepil tey anli vdceiltbci witls aw ftouil ptvi ai sn\n",
      "re aw wndepil tem anli vdceiltbci witls aw ftouil ptvi ai sn\n",
      "re ay yndepil tem anli vdceiltbci yitls ay ftouil ptvi ai sn\n",
      "re ay yndepil tem anli vdceiltbci yitls ay ftouil ptvi ai sn\n",
      "re ay yndepil tem anli vdceilthci yitls ay gtouil ptvi ai sn\n",
      "re ay yndepil tem anli wdceilthci yitls ay gtouil ptwi ai sn\n",
      "re ay yndepil tem anli wdceilthci yitls ay gtouil ptwi ai sn\n",
      "re ay yndepil tem anli wdceilthci yitls ay gtouil ptwi ai sn\n",
      "re ay yndepil tem anli wdfeilthfi yitls ay gtouil ptwi ai sn\n",
      "re ay yndepil tem anli wdfeilthfi yitls ay gtouil ptwi ai sn\n",
      "re ay yndepil tem anli wdfeilthfi yitls ay gtouil ptwi ai sn\n",
      "re ay yndepil tem anli wdfeilthfi yitls ay gtouil ptwi ai sn\n",
      "re ay yndepil tem anli wdfeilthfi yitls ay gtouil ptwi ai sn\n",
      "re ay yndepil tem anli kdfeilthfi yitls ay gtouil ptki ai sn\n",
      "re ay yndepil tem anli kdfeilthfi yitls ay gtouil ptki ai sn\n",
      "re ay yndepil tem anli kdfeilthfi yitls ay gtouil ptki ai sn\n",
      "re ay ynlepid tem andi klfeidthfi yitds ay gtouid ptki ai sn\n",
      "re ay ynlepid tem andi klfeidthfi yitds ay gtouid ptki ai sn\n",
      "re ay ynlepid tem andi vlfeidthfi yitds ay gtouid ptvi ai sn\n",
      "re ay ynlepid tem andi vlfeidthfi yitds ay gtouid ptvi ai sn\n",
      "re ay ynlepid tem andi vlfeidthfi yitds ay gtouid ptvi ai sn\n",
      "re ay ynlepid tem andi vlfeidthfi yitds ay gtouid ptvi ai sn\n",
      "re ay ynlepid tem andi vlfeidthfi yitds ay gtouid ptvi ai sn\n",
      "re ay ynlepid tem andi klfeidthfi yitds ay gtouid ptki ai sn\n",
      "re ay ynlepid tem andi klfeidthfi yitds ay gtouid ptki ai sn\n",
      "re ay ynlepid tem andi klfeidthfi yitds ay gtouid ptki ai sn\n",
      "re ay ynlepid tem andi klfeidthfi yitds ay gtouid ptki ai sn\n",
      "ri ay ynliped tim ande klfiedthfe yetds ay gtoued ptke ae sn\n",
      "ri ak knliped tim ande ylhiedtfhe ketds ak gtoued ptye ae sn\n",
      "ri ak knliped tim ande ylhiedtfhe ketds ak gtoued ptye ae sn\n",
      "ri nk kaliped tim nade ylhiedtche ketds nk gtoued ptye ne sa\n",
      "ri nk kalifed tim nade ylhiedtche ketds nk gtoued ftye ne sa\n",
      "ri nk kalifed tim nade ylhiedtche ketds nk gtoued ftye ne sa\n",
      "ri ny yalifed tim nade klhiedtche yetds ny gtoued ftke ne sa\n",
      "ri ny yalifed tim nade klhiedtche yetds ny gtoued ftke ne sa\n",
      "ri ny yalifed tim nade klhiedtche yetds ny gtoued ftke ne sa\n",
      "ri ny yalifed tim nade klhiedtche yetds ny gtoued ftke ne sa\n",
      "ir ny yalrfes trm nase klhrestche yetsd ny gtoues ftke ne da\n",
      "ir ny yalrfes trm nase klhrestche yetsd ny gtoues ftke ne da\n",
      "ir ny yalrfes trm nase klhrestche yetsd ny gtoues ftke ne da\n",
      "ir ny yalrfes trm nase klhrestche yetsd ny gtoues ftke ne da\n",
      "ir ny yalrfes trm nase klhrestche yetsd ny gtoues ftke ne da\n",
      "ir sy yalrfen trm sane klhrentche yetnd sy gtouen ftke se da\n",
      "ir sy yalrfen trm sane klhrentche yetnd sy gtouen ftke se da\n",
      "ir sy yalrfen trm sane klhrentche yetnd sy gtouen ftke se da\n",
      "ir sy yalrfen trm sane klhrentche yetnd sy gtouen ftke se da\n",
      "ir sy yalrfen trm sane klhrentche yetnd sy gtouen ftke se da\n",
      "ir sy yalrfen trm sane klhrentche yetnd sy gtouen ftke se da\n",
      "ir sy yalrfen trm sane klhrentche yetnd sy gtouen ftke se da\n",
      "ir sy yalrfen trm sane klhrentche yetnd sy gtouen ftke se da\n",
      "ir sy yalrfen trm sane klhrentche yetnd sy gtouen ftke se da\n",
      "ir sy yalrfen trm sane klhrentche yetnd sy gtouen ftke se da\n",
      "ir sy yalrfen trm sane klhrentche yetnd sy gtouen ftke se da\n",
      "ir sy yalrfen trm sane klhrentche yetnd sy gtouen ftke se da\n",
      "ir sy yalrfen trm sane klhrentche yetnd sy gtouen ftke se da\n",
      "ir hy yalrfen trm hane klsrentcse yetnd hy gtouen ftke he da\n",
      "ir hy yalrpen trm hane vlsrentcse yetnd hy gtouen ptve he da\n",
      "ir cy yalrpen trm cane vlsrenthse yetnd cy gtouen ptve ce da\n",
      "ir cy yalrpen trm cane vlsrenthse yetnd cy gtouen ptve ce da\n",
      "ir cy yalrpen trm cane vlsrenthse yetnd cy gtouen ptve ce da\n",
      "ir cy yalrpen trm cane vlsrenthse yetnd cy gtouen ptve ce da\n",
      "ir cy yalrpen trm cane vlsrenthse yetnd cy gtouen ptve ce da\n",
      "ir cy yalrpen trm cane vlsrenthse yetnd cy gtouen ptve ce da\n",
      "ir cy yalrpen trm cane vlsrenthse yetnd cy gtouen ptve ce da\n",
      "ir cy yalrpen trm cane vlsrenthse yetnd cy gtouen ptve ce da\n",
      "ir cy yalrpen orm cane vlsrenohse yeond cy gotuen pove ce da\n",
      "ir cu ualrpen orm cane vlsrenohse ueond cu gotyen pove ce da\n",
      "in cu ualnper onm care vldnerohde ueors cu gotyer pove ce sa\n",
      "in ch haunper onm care vudnerolde heors ch gotyer pove ce sa\n",
      "in ch haunper onm care vudnerolde heors ch gotyer pove ce sa\n",
      "in cy yaunper onm care vudnerolde yeors cy gother pove ce sa\n",
      "in cy yaunper onm care vulnerodle yeors cy gother pove ce sa\n",
      "in cy yaunper onm care vulneroble yeors cy gother pove ce sa\n",
      "in cy yaunper onm care vulneroble yeors cy gother pove ce sa\n",
      "in cy yaunger onm care vulneroble yeors cy pother gove ce sa\n",
      "in cy yaunger onm care vulneroble yeors cy pother gove ce sa\n",
      "in cy younger anm core vulnerawle years cy pather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anf core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy wather gave ce so\n",
      "in cy younger anm core vulneraple years cy father gave ce so\n",
      "in cy younger anm core vulneraple years cy father gave ce so\n",
      "in dy younger anm dore vulneraple years dy father gave de so\n",
      "in dy younger anm dore vulneraple years dy father gave de so\n",
      "in dy younger anm dore vulneraple years dy father gave de so\n",
      "in dy younger anm dore vulneraple years dy father gave de so\n",
      "in dy younger anm dore vulneraple years dy father gave de so\n",
      "in dy younger anm dore vulneraple years dy father gave de so\n",
      "in dy younger anm dore vulneraple years dy father gave de so\n",
      "in dy younger anm dore vulneraple years dy father gave de so\n",
      "in dy younger anm dore vulneraple years dy father gave de so\n",
      "in dy younger anm dore vulneraple years dy father gave de so\n",
      "in dy younger anm dore vulneraple years dy father gave de so\n",
      "in dy younger anm dore vulneraple years dy father gave de so\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in dy younger anm dore vulnerable years dy father gave de so\n",
      "in dy younger anm dore vulnerawle years dy father gave de so\n",
      "in dy younger anm dore vulnerawle years dy father gave de so\n",
      "in dy younger anm dore vulnerawle years dy father gave de so\n",
      "in dy younger anm dore vulnerawle years dy father gave de so\n",
      "in dy younger anm dore vulnerawle years dy father gave de so\n",
      "in dy younger anm dore vulnerawle years dy father gave de so\n",
      "in dy younger anm dore vulnerawle years dy father gave de so\n",
      "in dy younger anm dore vulnerawle years dy father gave de so\n",
      "in dy younger anm dore vulnerawle years dy father gave de so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my wather gave me so\n",
      "in my younger and more vulnerable years my pather gave me so\n",
      "in my younger and more vulnerable years my pather gave me so\n",
      "in my younger and more vulnerable years my pather gave me so\n",
      "in my younger and more vulnerable years my pather gave me so\n",
      "in my younger and more vulnerable years my pather gave me so\n",
      "in my younger and more vulnerable years my pather gave me so\n",
      "in my younger and more vulnerable years my pather gave me so\n",
      "in my younger and more vulnerable years my pather gave me so\n",
      "in my younger and more vulnerable years my pather gave me so\n",
      "in my younger and more vulnerable years my pather gave me so\n",
      "in my younger and more vulnerable years my pather gave me so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my father gave me so\n",
      "in my younger and more vulnerable years my father gave me some advice that ixve been turning over in my mind ever since. *whenever you feel like criticizing any one,* he told me, *just remember that all the people in this world havenxt had the advantages that youxve had.* he didnxt say any more but wexve always been unusually communicative in a reserved way, and i understood that he meant a great deal more than that. in consequence ixm inclined to reserve all judgments, a habit that has opened up many curious natures to me and also made me the victim of not a few veteran bores. the abnormal mind is quick to detect and attach itself to this quality when it appears in a normal person, and so it came about that in college i was unjustly accused of being a politician, because i was privy to the secret griefs of wild, unknown men. most of the confidences were unsought--frequently i have feigned sleep, preoccupation, or a hostile levity when i realized by some unmistakable sign that an intimate revelation was quivering on the horizon--for the intimate revelations of young men or at least the terms in which they e?press them are usually plagiaristic and marred by obvious suppressions. reserving judgments is a matter of infinite hope. i am still a little afraid of missing something if i forget that, as my father snobbishly suggested, and i snobbishly repeat a sense of the fundamental decencies is parcelled out unequally at birth.\n"
     ]
    }
   ],
   "source": [
    "MCMC(20001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4928d3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
