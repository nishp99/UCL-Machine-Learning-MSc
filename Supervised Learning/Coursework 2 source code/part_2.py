# -*- coding: utf-8 -*-
"""Part 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i-rCMyq5TGC52jE5FjM6IfjenAt6CFWP
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
import re

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

"""
load all the data into a nice format
"""
two_moons_data = list(open('/content/drive/MyDrive/supervisedcoursework/twomoons.dat','r'))
two_moons_raw = [[float(x) for x in list(filter(None,re.split(' |\n',i)))] for i in two_moons_data]
two_moons_tensor = torch.tensor(two_moons_raw)
two_moons_X = two_moons_tensor[:,1:]
two_moons_y = two_moons_tensor[:,0]

"""
computes the weight matrix from a given c
and data X
"""
def weight_matrix(c,X):
  return torch.exp(-c*torch.cdist(X, X))

"""
computes the degree matrix by summing the columns of the weight matrix
"""
def degree_matrix(W):
  D = torch.sum(W,dim=0)
  return torch.diag(D)

"""
returns the predicted cluster vector of the data which produces the 
Laplacian 'L'. It does this by taking the sign of the eigenvector
corresponding the the second smallest eigenvalue, and sets all 0 
elements to +1.
"""
def cluster_vector(L):
  values, vectors = torch.linalg.eigh(L)
  clusts = torch.sign(vectors[:,1])
  clusts[clusts==0] = 1
  return clusts

def scatter_original(X,x_lim,y_lim):
  plt.scatter(X[:,0], X[:,1]);
  plt.xlim(x_lim[0],x_lim[1])
  plt.ylim(y_lim[0],y_lim[1])

def scatter_clustered(X,y,x_lim,y_lim):
  plt.scatter(X[:,0], X[:,1], c=y, cmap='autumn', edgecolor='k');
  plt.xlim(x_lim[0],x_lim[1])
  plt.ylim(y_lim[0],y_lim[1])

"""
generates data samples from 2 different 2D gaussians
"""
def generate_data():
  X_1 = torch.normal(-0.3*torch.ones(20,2),0.2**torch.ones(20,2))
  X_2 = torch.normal(0.15*torch.ones(20,2),0.1**torch.ones(20,2))

  X = torch.concat((X_1,X_2), dim = 0)
  y = torch.tensor((20*[-1] + 20*[1]))
  return X, y

"""
removes all data corresponding to the digit '2' from dtrain123.
And then relabels '3' to '-1'
"""
def remove_2(X,y):
    y = y - 2*torch.ones_like(y)
    y_mask = ~torch.eq(y,torch.zeros_like(y))
    X_mask = (y_mask.unsqueeze(1)).repeat(1,256)

    X_clean = torch.masked_select(X,X_mask).view(-1,256)
    y_clean = torch.masked_select(-y,y_mask)
    return X_clean, y_clean

"""
calculates the percentage of points that are clustered correctly.
It compares the predicted clusters (cluster_vector) with actual
clusters (y) 
"""
def cluster_percentage(cluster_vector,y):
  correct = torch.eq(cluster_vector,y)
  l = y.size()[0]
  l_plus = torch.sum(correct)
  l_minus = l - l_plus
  return max(l_plus,l_minus)/l

scatter_clustered(two_moons_X,two_moons_y, (-2,4),(-1,1.5))

scatter_original(two_moons_X, (-2,4),(-1,1.5))
plt.title('Original data')

"""
function that clusters X, tests the accuracy of clusters
against y, and plots the data
"""
def cluster_c(c,X,y, x_lim, y_lim):
  W = weight_matrix(c,X)
  D = degree_matrix(W)
  L = D - W
  classes = cluster_vector(L)
  scatter_clustered(X,classes, x_lim, y_lim)
  print(cluster_percentage(classes, y))

cluster_c(2**4.5,two_moons_X,two_moons_y, (-2,4),(-1,1.5))
plt.title('Spectral clustering algorithm')

synthetic_X, synthetic_y = generate_data()

scatter_original(synthetic_X, (-1,1), (-1,1))
plt.title('Original data')

cluster_c(2**1, synthetic_X, synthetic_y, (-1,1), (-1,1))
plt.title('Spectral clustering algorithm')

"""
load the real digit data and clean to a nice format
"""
mini_train = list(open('/content/drive/MyDrive/supervisedcoursework/minitrain.dat','r'))
mini_train_raw = [[float(x) for x in re.split(' +',i)] for i in mini_train]
mini_train_tensor = torch.tensor(mini_train_raw)
digits_y = mini_train_tensor[:,0]
digits_X = mini_train_tensor[:,1:]

"""
remove all the rows corresponding to 2, and relabel 1,3 to 1,-1 respectively
"""
real_X, real_y = remove_2(digits_X, digits_y)

"""
cluster function that doesn't include plots
"""
def cluster_real(c,X,y):
  W = weight_matrix(c,X)
  D = degree_matrix(W)
  L = D - W
  classes = cluster_vector(L)
  return cluster_percentage(classes, y).item()

iterator = [i/1000 for i in range(401)]
percentages = []
for x in iterator:
  percentages.append(cluster_real(x, real_X, real_y))

plt.plot(iterator,percentages)
plt.xlabel('c (scale factor of the Gaussian)')
plt.ylabel('Correct cluster fraction')
plt.title('Model selection of parameters')
max_value = max(percentages)
max_index = percentages.index(max_value)
print(iterator[max_index])